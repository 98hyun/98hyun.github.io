title: 2021-04-30
author: 98hyun
description: 
published: 2021-04-30
tags: [시각화, 개발환경, 딥러닝, 데이터분석]

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; colab에서 kaggle api로 작업하기.</h3>

<details><summary>code</summary><blockquote><pre><code>

# terminal code
!pip install kaggle

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
  
# Then move kaggle.json into the folder where the API expects to find it.
!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json

# download
!kaggle competitions download -c sejong-ai-challenge-p2
!unzip sejong-ai-challenge-p2.zip

# read data 
import pandas as pd
pd.read_csv('/content/test.csv.zip')

</code></pre></blockquote></details>

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; <a href="https://www.kaggle.com/ritesh2000/bert-all-in-one">BERT 참고</a></h3>

구글이 풀어놓은 nlp 프로세싱인데 미리 훈련된 딥러닝 방법이다. 쉽게 말해서 가져다 쓰면 되는것이다. 위에 본문 링크를 걸어놨다. 

구글 번역기 키고 보면 2번 코딩 전까지 넉넉히 15분 걸린다. 

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; fasttext</h3>

fasttext는 facebook이 만든 nlp문제를 쉽게 다가올 수 있게 한 라이브러리다.   

어떻게 작용하는지는 잘 모르지만, 간단하게 분류 모델을 만들수 있다.  

문제는 [캐글 소설 작가 분류 문제](https://www.kaggle.com/c/spooky-author-identification)이고, 공부해본 내용이다. [참고](https://www.kaggle.com/hwangchanghyun/fasttext-tutorial)

<details><summary>code</summary><blockquote><pre><code>

... snip

# X_tr은 원래 데이터를 train과 valid으로 나눈 것 중 train이다.
for i,row in X_tr.iterrows():
    target=y_tr.loc[i]
    # target을 앞에 prefix로 붙여야한다. 규칙.  
    label=f'__label__{target}' 
    text=row['keyword']+' '+row['location']+' '+row['text']
    label+=' '+text
    tr_arr.append(label)
    
for i,row in X_val.iterrows(): 
    # train을 나눈것이니 label은 정해져있다. validation을 위해 나뒀다.  
    text=row['keyword']+' '+row['location']+' '+row['text']
    val_arr.append(text)
    
for i,row in test.iterrows():
    text=row['keyword']+' '+row['location']+' '+row['text']
    test_arr.append(text)

train_df=pd.DataFrame(tr_arr)
# 나중에 파일 경로를 입력해줘야해서 새로운 train파일을 만든것이다. 
# quotechar은 "" 쌍따옴표 이거 인용구 만들려고 쓴다. 없앤것이다. 
# index는 당연 false, header도 false 한다. 중요. quoting은 escapechar과 같이 쓰인다. 
# escapechar은 인용구안하고 구분 어떻게 할껀데? 이런 뜻이다. 안한다는 뜻이다.
train_df.to_csv('train.txt',index=False,sep=' ',header=False,quoting=csv.QUOTE_NONE,quotechar="",escapechar=" ")

# model
model=fasttext.train_supervised('train.txt',label_prefix='__label__',epoch=10)
print(model.labels,'are the labels or targets the model is predicting')

# 예측 예측한것의 label은 [__label__{pred}] 형식의 리스트안의 문자열로 나온다. 
# 그래서 0으로 리스트index로 접근하고 마지막 글자만 가져왔다. 
# 만약 문자열로 정의한다면 .split('__')[-1]으로 접근하면 된다. 
pred=[int(label[0][-1]) for label in model.predict(test_arr)[0]]
... endsnip 
</code></pre></blockquote></details>

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; 도커</h3>

핵심 개념. image, container, dockerfile 

image - 컨테이너 생성을 위한 틀.   
container - 이미지를 바탕으로 실행되는 독립된 프로세스.  
dockerfile - 이미지를 만들기 위해 코드 형태로 기록한 파일.    

<details><summary>code</summary><blockquote><pre><code>

</code></pre></blockquote></details>

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; Clustering</h3>

* [K-Means clustering](https://eunsukimme.github.io/ml/2019/12/16/K-Means/)

랜덤으로 k개의 centroids를 정한다. 그리고 각각의 object에 대해서 centorids와의 거리들을 계산한 후, 가까운 centroid에 label을 입력한다. 그 후 그룹의 object들의 x,y좌표를 평균으로 새로운 x,y를 만든 후 같은 작업을 하면서 object들의 움직임이 멈추고 centroids가 바뀌지 않으면 알고리즘을 멈춘다. 

inertia와 cluster는 trade-off 관계에 있기 때문에 elbow방법을 사용한다.  

<details><summary>code</summary><blockquote><pre><code>
fig, ax = plt.subplots(figsize=(15,7))

clusters_range = [2,3,4,5,6,7,8,9,10,11,12,13,14]
inertias =[]

for c in clusters_range:
    kmeans = KMeans(n_clusters=c, random_state=0).fit(cluster_scaled)
    inertias.append(kmeans.inertia_)

plt.plot(clusters_range,inertias, '-' , color='#244747',alpha = 0.8,linewidth=8)
plt.plot(clusters_range,inertias, 'o',linewidth=20,color='#d4dddd')    


plt.xlabel('Number of Clusters',fontsize=12) , plt.ylabel('Inertia',fontsize=12)
ax.xaxis.set_ticks(np.arange(2,15,1))

# Title & Subtitle
fig.text(0.12,0.96,'Age, annual income and spending score', fontfamily='serif',fontsize=15, fontweight='bold')
fig.text(0.12,0.92,'We want to select a point where inertia is low, and the number of clusters is not overwhelming for the business.',fontfamily='serif',fontsize=12)


ax.annotate(" We'll select 6 clusters", 
            xy=(4.5, 100), fontsize=12,
            va = 'center', ha='center',
            color='#4a4a4a',
            bbox=dict(boxstyle='round', pad=0.4, facecolor='#efe8d1', linewidth=0))

# Grid
ax.set_axisbelow(True)# Ax spines
ax.spines['top'].set_visible(False)
ax.spines['bottom'].set_visible(True)
ax.spines['left'].set_visible(True)
ax.spines['right'].set_visible(False)

ax.spines['left'].set_color('lightgray')
ax.spines['bottom'].set_color('lightgray')
ax.yaxis.grid(color='lightgray', linestyle='-')
plt.show()
</code></pre></blockquote></details>

![](https://ifh.cc/g/HYzI1v.png) 

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; 분류 목적함수</h3>

손실함수가 최소화/최대화 되는 목적함수
분류가 잘됐는지 확인하는 목적 함수를 잘 설정해야 모델이 학습을 잘 할 것이다.  

<table>
    <thead>
        <tr>
            <th></th>
            <th></th>
            <th></th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=2 colspan=2> </td>
            <td colspan=2 style="text-align:center;">실제</td>
        </tr>
        <tr>
            <td style="text-align:center;">양성</td>
            <td style="text-align:center;">음성</td>
        </tr>
        <tr>
            <td rowspan=2 style="text-align:center;">예측</td>
            <td>양성</td>
            <td style="text-align:center;">True Positive</td>
            <td style="text-align:center;">False Negative<br>1종 오류.</td>
        </tr>
        <tr>
            <td>음성</td>
            <td style="text-align:center;">False Negative<br>2종 오류.</td>
            <td style="text-align:center;">True Negative</td>
        </tr>
    </tbody>
</table>


<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; Time Series EDA</h3>

시계열 데이터를 분석할 때 주의할 점을 코드로 적었다. [참고](https://www.kaggle.com/andreshg/timeseries-analysis-a-complete-guide)

<details><summary>code</summary><blockquote><pre><code>

# 0. 시간 변수 처리
# 모양에 따라 format 처리. 만약, 20210430이라면 "%Y%m%d"가 맞고, 30/04/2021이라면 "%d/%m/%Y".
df['date'] = pd.to_datetime(df['date'], format = '%Y%m%d') 

# 1. data visualization 
# 다른 독립변수와 시간변수간 분포 그래프. 

# 2. data preprocessing
# 2-1. 순서대로 되어있는지, 빈 구간은 없는지 확인.
df = df.sort_values(by='date')

df['delta'] = df['date'] - df['date'].shift(1)
print(df['delta'].sum(), df['delta'].count())

# 2-2. 결측값이 있는지. 
# 만약 있다면, 첫번째. 아예 -999로 채우거나 0으로 두기. 
# 평균이나 앞의 값으로 채우기. 혹은 주변값과 interpolate하기. 

# 2-3. resampling 
# 7D는 7Days를 의미한다. 15D, M은 month를 의미한다. 여러가지를 해보고 결정한다. 
df.resample('7D', on='date').mean().reset_index(drop=False)

# 2-4. stationary
# 3가지로 본다. visual, basic statistic, statistic test. 
# 그 중 통계방법은 adfuller로 귀무가설(단위근을 가지고, 비정상성이다.)과 대립가설(단위근이 없고, 정상성이다.)로 나눠서 검정한다. 
# 당연하지만, p-value(1종오류가 일어날 확률)가 유의수준보다 낮으면 귀무가설을 기각한다. 
# critical value 보다 adf-statistic 점수가 낮아도 귀무가설을 기각할 수 있다. 

# https://www.statsmodels.org/stable/generated/statsmodels.tsa.stattools.adfuller.html
from statsmodels.tsa.stattools import adfuller

result = adfuller(df['depth_to_groundwater'].values)

### result
(-2.880201649316658, ## adf-statistic 
 0.04769919092020916, ## p-value
 7, 
 592,
 {'1%': -3.441444394224128, ## critical value in 1%
  '5%': -2.8664345376276454, ## critical value in 5%
  '10%': -2.569376663737217}, ## critical value in 10%
 -734.3154255877625)

# 2-5. 필요에 따라 변환과 차분을 한다. 
# 후에 feature engineering 까지 한다. 

# 3. 이제 시계열 분해(decomposition)을 통해 4가지를 밝힌다. 
# Level, Trend, Seasonality, Noise 위 관계가 덧셈이면 additive 모델, 곱셈이면 multiplicative 모델. 

# 3-1. eda와 acf,pacf를 통해 모델의 방향을 결정한다. 

# 4. 모델링을 한다. 
</code></pre></blockquote></details>

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; plotly </h3>

<details><summary>code</summary><blockquote><pre><code>

</code></pre></blockquote></details>

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; kaggle courses </h3>

캐글에 간단하게 개념들을 배울 수 있는 course들이 있다. bigquery만 공부해봤다. [참고](https://www.kaggle.com/learn/intro-to-sql)  

<details><summary>code</summary><blockquote><pre><code>

# library 
from google.cloud import bigquery
from bq_helper import BigQueryHelper
client=bigquery.Client()

# basic code
query=\
"""
select * from `bigquery-public-data.google_analytics_sample.ga_sessions_20170801`
limit 10
"""
job=client.query(query)
df=job.to_dataframe()

# browse 
bqh=BigQueryHelper('bigquery-public-data','google_analytics_sample')
print(bqh.table_list()[:3]) # 3개 table 보기.
print(bqh.head('ga_sessions_20170801',num_rows=5)) # pandas head와 같은 역할. 

# {'index':...,'value':...,'top':...} 형태. 
query=\
"""
select * from unnest(array(select totals from `bigquery-public-data.google_analytics_sample.ga_sessions_*` # 와일드카드
where _table_suffix between '20170701' and '20170731'))
"""

# [{'index':...,'value':...}] 형태.
query=
"""
select param.index,param.value from `bigquery-public-data.google_analytics_sample.ga_sessions_*`
,unnest(customDimensions) as param 
-- param = alias. # --은 주석
where _table_suffix between '20170701' and '20170731'
"""
</code></pre></blockquote></details>

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; </h3>

<details><summary>code</summary><blockquote><pre><code>

</code></pre></blockquote></details>

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; </h3>

<details><summary>code</summary><blockquote><pre><code>

</code></pre></blockquote></details>