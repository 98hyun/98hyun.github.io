title: 2021-05-31
author: 98hyun
published:
description: 지난번 모델 성능 지표인 분류표를 업데이트했고, logloss에 대해서 dacon문제와 연결지어 코드를 보여준다. 그 외로 R을 활용한 기술통계량을 보는 방법과 통계검정 방법들을 보여준다. python과 mongodb, python과 selenium을 활용해서 xrp historical 데이터를 parsing 하는것을 보여준다. 
tags: [데이터분석, 데이터베이스]

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; 20210430 post update</h3>

20210430 post에 분류표를 평가하기 위한 기준에 대해서 설명한 내용들을 코드와 함께 추가 했다. [update 내용 보러가기](https://98hyun.github.io/posts/20210430.html)

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; logloss</h3>

[신용카드 사용자 연체 예측 AI 경진대회](https://dacon.io/competitions/official/235713/overview/description)를 풀며 생각한 내용이다. logloss는 보통 multi classfication문제에 많이 등장한다. 

만약 보기 5개가 있는 문제의 정답을 1로 '나 이거 알아'한 사람의 정답과 '헷갈리는데 이거'로 한 사람의 정답은 같다고 볼 수 있을까? 

logloss는 모델이 예측한 확률 값을 직접적으로 반영하여 평가한다. 정확히 말하면 음의 log함수에 넣어서 확률값을 변환을 시킨 값이다. 즉, 잘못 예측할수록, 패널티를 부여한다.

<details><summary>code</summary><blockquote><pre><code>

## 아래 코드는 직접 사용한 코드를 가져왔다. 모든 코드를 보려면 https://www.kaggle.com/hwangchanghyun/dacon14 보면 된다. 
## 주목할 점은 objective 와 eval_metric이다. 
## objective는 '뭐 할꺼야?'의 답을 나타낸다. eval_metric은 '잘 되고있는지 봐줄게'다.

## logloss는 확률값을 알려준다고 했다. 즉, 1 2 3을 알아맞추는데 0.1 0.1 0.8이라고 알려준다.
## 분류표를 기억한다면 조금 낯설것이다. 정확히 0또는 1로 떨어지는 값이 아닌 어떤 값이 될 확률을 알려주니. 신용카드문제가 점수 채점을 logloss로 해서 그렇다.

import xgboost as xgb

params={
    'objective':'multi:softprob'
    ## multi:softmax도 있다. softmax로 하면 0,1 로 나뉘는것이다. 
    ## 자연스럽게 eval_metric도 merror로 바뀐다.
    'random_state':71,
    'n_estimators':1000
}
model=xgb.XGBClassifier(**params)

model.fit(X_train,y_train,
          eval_set=[(X_train, y_train),(X_test,y_test)],
          eval_metric='mlogloss',verbose=True,
          early_stopping_rounds=10)
</code></pre></blockquote></details>

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp; basic statistic </h3>

R을 사용하여 통계검정 방법들을 공부했다.  
한번 알아두면 쉽게 할 수있는 방법들이다.

<details><summary>code</summary><blockquote><pre><code>

## 1. 기술통계
mystats=function(x,na.omit=F){ 
    if(na.omit){
        x=x[!is.na(x)]
    }
    m=mean(x) 
    n=length(x) 
    s=sd(x)
    skew=sum((x-m)^3/s^3)/n
    kurt=sum((x-m)^4/s^4)/n-3
    return (c(n=n,mean=m,stdev=s,skew=skew,kurosis=kurt))
}

option(digits=3) ## 가독성을 높이기 위해 소수점 3자리 유지
sapply(data.frame,mystats) 

-- 추가로 쉽게 이걸로 가능.
library(psych)
describe(data.frame)

## 2. 독립 검정
## 카이제곱검정 - categorical + categorical

twt=xtabs(~col1+col2,data=data.frame) 
chisq.test(twt) 

## 만약 cell의 20%가 기대빈도가 5보다 작다면 
## fisher's exact test.

fisher.test(twt)

## cochran-mantel-haenszel test (CMH)
## 세번째 범주형 변수가 두 이항변수의 조건부 연관성을 검정할 때

twt=xtabs(~col1+col2+col3,data=data.frame)
mantelhaen.test(twt) ## col3 가 영향을 준다고 가정.

## 3. 상관계수
## 연속형 상관계수
cor(data.frame) ## method : pearson, spearman
cor.test(data.frame[,3],data.frame[,5]) ## 3번,5번 상관관계 검정
## 편상관계수 구하기
## 첫번째(1)와 두번째(5)의 상관관계가 (2,3,6)의 제어조건을 받고 상관과계가 있나를 확인한다.
library(ggm)
pcor(c(1,5,2,3,6),stats:cov(states)) 

## 4. t.test 그룹 비교 검정 
## 독립검정 - 범주~연속
t.test(group~cont,data=data.frame)) 

## 짝검정 - 연속,연속
with(data.frame,t.test(col1,col2,paired=T))

## 5. 셋 이상의 그룹 비교 
## 독립성,등분산,정규성을 만족한다면 anova
summary(aov(cont~group,data=data.frame))

## 가정을 만족못한다 - 비모수 kruskal
kruskal.test(cont~group,data=data.frame)

## 6. 설문지 신뢰도
## 특징. 1에 가까울수록 성능이 좋다.(보통 0.6~0.8)
## 특징. 변수를 제거했을 때 크론바하 a 값이 커지면 변수를 제외한다.
## 특징. 문항의 수가 a값에 포함되기 때문에 적정한 수의 문항도 있어야한다.

library(psych)
alpha(data.frame)
</code></pre></blockquote></details>

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp;mongodb</h3>

NoSQL은 초당 데이터가 수십만개씩 쌓이는 서비스에서 많이 사용된다. mongodb은 대표적인 NoSQL프로그램이다. json형식의 document기반으로 데이터를 관리한다. 

프로그램이 있고 mongodb전용 cli도 있다. 이번엔 python으로 control 했다. 

저장되어있는 data를 가져와서 pandas dataframe으로 바꾸는 과정을 썼다. 보통 data handling은 pandas가 편해서 그렇다. 잘 사용할 수 있는걸로 하면 된다.

데이터를 저장하는 방식은 밑의 selenium 파트에서 할 것이다.

<details><summary>code</summary><blockquote><pre><code>

## 순서는 다음과 같다. 
## library가져오고, db에 접근해서
## pandas로 만든다.
## library
import pandas as pd

from pymongo import MongoClient
client=MongoClient('localhost',27017)
db=client.coin 
xrp=db.xrp 
## coin db의 xrp document를 의미한다. SQL의 table은 mongodb의 colletion이고, 
## SQL의 각각의 row들이 mongodb의 document에 해당한다.

all_docs=xrp.find()

lst=[]
for docs in all_docs:
    data=[docs['year'],docs['start'][1:],docs['high'][1:],
    docs['low'][1:],docs['end'][1:],docs['volume'][1:],docs['price'][1:]]
    if data not in lst:
        lst.append(data)

## 본인이 자주쓰는 data frame을 만드는 방법이 2가지 있다. 
## 1. list형식으로 여러 row를 만들어서 한번에 집어넣기.
## 2. dict형식으로 column과 데이터(list형식)를 짝지어 한번에 집어넣기.
## 이번엔 1번 방법으로 했다.

df=pd.DataFrame(lst,columns=['year','start','high','low','end','volume','price'])
df.to_csv('5Yxrp.csv',index=False)

</code></pre></blockquote></details>

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp;selenium</h3>

mongodb를 사용한 이유다. 코인 시가총액 데이터를 긁어오기 위해서 selenium을 사용했고, 관련 데이터를 저장하기위해서 mongodb를 이용한 것이다. 

selenium은 보통 정적인 웹사이트가 아닌 동적인 웹사이트를 parsing할 때 많이 사용한다. 

이번 프로젝트 데이터 수집 코드를 가져왔다.

<details><summary>code</summary><blockquote><pre><code>

## 기본적인 selenium을 활용한 crawl은 인터넷에 많다.
## 이번에는 button을 눌러서 새로운 데이터가 계속 나타나게 하는 작업을 진행했다.
## ripple coin의 5개년 데이터를 가져왔다.

## library
from selenium import webdriver
import time

from pymongo import MongoClient
client=MongoClient('localhost', 27017)
db=client.coin
xrp=db.xrp

## option 들을 보통 넣어주는 편이다. 
options=webdriver.ChromeOptions()
# options.headless=True
options.add_argument('window-size=1920x1080')
options.add_experimental_option("excludeSwitches", ["enable-logging"])
options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36')

browser=webdriver.Chrome('./chromedriver_win32/chromedriver.exe',
options=options)

url='https://coinmarketcap.com/ko/currencies/xrp/historical-data/'
browser.get(url)
time.sleep(3)

count=0
button='//*[@id="__next"]/div/div[1]/div[2]/div/div[3]/div/div/p[1]/button'

y=3500 ## 처음 버튼의 위치다. 자동화중에 이게 계속 보이게 하는게 중요하다.
while count!=61:
    # 선택
    browser.execute_script(f'window.scrollTo(0, {y});')
    browser.find_elements_by_xpath(button)[0].click()
    # 대기
    time.sleep(3)
    # 조건
    ## 한번 클릭에 1개월치 이므로, 1*12*5 즉, 60. 61은 그냥 했다.
    count+=1
    ## selenium은 자동화될때 버튼이 화면에 보여야한다. 중요하다.
    ## 1500의 높이를 확인했는데 정확하게 원위치가 안돼서 5번의 한번꼴로 높이를 올려주었다.
    y+=1500
    if count%5==0:
        y+=190

## 운이 좋게 tbody tag가 하나밖에 없었다. 
## find_element_by ~ 는 많다. xpath도 있고, tag name도 있고 그렇다.
trs=browser.find_elements_by_css_selector('tbody tr')
# print(trs)
# print(f"len(trs) : {len(trs)}")
for tr in trs:
    lst=tr.text.split(' ')

    year=lst[0]+' '+lst[1]+' '+lst[2]
    start=lst[3]
    high=lst[4]
    low=lst[5]
    end=lst[6]
    volume=lst[7]
    price=lst[8]

    data={
        'year':year,
        'start':start,
        'high':high,
        'low':low,
        'end':end,
        'volume':volume,
        'price':price
    }

    # print(data)
    ## 별거 없다. 하나씩 넣을 땐 insert_one 여러개 한번에 넣을땐 리스트에 모아두고 insert_many.
    ## 단, 그냥 따옴표는 안되고, "" 쌍따옴표만 되는것 같다. 
    xrp.insert_one(data)

time.sleep(7)
browser.quit()

</code></pre></blockquote></details>

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp;ROC Curve</h3>


<details><summary>code</summary><blockquote><pre><code>
</code></pre></blockquote></details>

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp;ROC Curve</h3>


<details><summary>code</summary><blockquote><pre><code>
</code></pre></blockquote></details>

<br>

<h3 style="border-left: solid 3px #0E6073;"><span style="background-color:#2e3f59"></span> &nbsp;ROC Curve</h3>


<details><summary>code</summary><blockquote><pre><code>
</code></pre></blockquote></details>

<br>
